# Analysing Survey Data in R
***
Notes taken during/inspired by the Datacamp course 'Analysing Survey Data in R' by Kelly McConville.

**_Course Handouts_**

* [Part 1 - Introduction to survey data](./files/SurveyDataInR/chapter1.pdf)
* [Part 2 - Exploring categorical data](./files/SurveyDataInR/chapter2.pdf)
* [Part 3 - Exploring quantitative data](./files/SurveyDataInR/chapter3.pdf)
* [Part 4 - Modeling quantitative data](./files/SurveyDataInR/chapter4.pdf)

## Introduction to survey data

Survey weights result from a complex sampling design.  They may be to compensate for non-response, or sometimes they are grossing weights so for instance, our single household may have a weight of 28,000 which would imply that household represents 28,000 households in our larger population.  We typically take n households from a sample s.  If we use standard mean calculations on our dataset, to for instance work out the mean household income, this would result in incorrect values, since the survey data needs to be weighted first.

```{r}
# First let's load the things we will need
library(dplyr)
library(ggplot2)
library(survey)

ce <- read.csv("./files/SurveyDataInR/ce.csv")

head(ce)
```

The column FINLWT21 is the final weight column, the third household (row) for instance represents 20,208 US households.

We often want to visualise the weights, using a histogram is one way we can achieve this.

```{r}
# Construct a histogram of the weights
ggplot(data = ce, mapping = aes(x = FINLWT21)) +
    geom_histogram()
```

If using a more complex sample design, we can use the Survey package in R by Thomas Lumley. Using this, we create our survey object using the svydesign command, where id = specifies the stages of the survey design e.g. id = ~1 would be a simpl random sample design or id = ~county + personid would be a clustered sample by county followed by person.  Since there is a finite number of people that we sample from, we specify this as fpc = ~ N1 + N2 which is number of counties (N1) followed by the number of people (N2).

Now we look at the Academic Performance Index (API) dataset from the survey package.

```{r}
# Load the data
data(api)

# Look at the apisrs dataset
glimpse(apisrs)
head(apisrs)

# Specify a simple random sampling for apisrs
apisrs_design <- svydesign(data = apisrs, weights = ~pw, fpc = ~fpc, id = ~1)

# Produce a summary of the design
summary(apisrs_design)

```

Often we use stratification as a way to improve the accuracy of the data.  There is a similar dataset called apistrat that we explire here.  The schools are stratified based on the school type stype where E = Elementary, M = Middle, and H = High School. For each school type, a simple random sample of schools was taken.

```{r}
# Glimpse the data
glimpse(apistrat)

# Summarize strata sample sizes
apistrat %>%
  count(stype)

# Specify the design
apistrat_design <- svydesign(data = apistrat, weights = ~pw, fpc = ~fpc, id = ~1, strata = ~stype)

# Look at the summary information stored in the design object
summary(apistrat_design)
```

In other instances, we may have a cluster design to help reduce cost, here we use the dataset apiclus2.  The schools were clustered based on school districts, dnum. Within a sampled school district, 5 schools were randomly selected for the sample. The schools are denoted by snum. The number of districts is given by fpc1 and the number of schools in the sampled districts is given by fpc2.

```{r}
# Glimpse the data
glimpse(apiclus2)

# Specify the design
apiclus_design <- svydesign(id = ~dnum + snum, data = apiclus2, weights = ~pw, fpc = ~fpc1 + fpc2)

#Look at the summary information stored in the design object
summary(apiclus_design)
```

An observation's survey weight tells us how many population units that observation represents. The weights are constructed based on the sampling design. Let's compare the weights for the three samples of the api dataset. For example, in simple random sampling, each unit has an equal chance of being sampled, so each observation gets an equal survey weight. Whereas, for stratified and cluster sampling, units have an unequal chance of being sampled and that is reflected in the survey weight.

```{r}
# Construct histogram of pw for SRS
ggplot(data = apisrs,
       mapping = aes(x = pw)) + 
    geom_histogram()

# Construct histogram of pw for stratificaiton
ggplot(data = apistrat,
       mapping = aes(x = pw)) + 
    geom_histogram()

# Construct histogram of pw for clustered design
ggplot(data = apiclus2,
       mapping = aes(x = pw)) + 
    geom_histogram()

```

### Analysing Weighted Data

Data often comes with multiple levels of survey design elements and associated weights.  For instance, the NHANES data or National Health and Nutrition Examination Survey, has a 5 stage process (somtimes referred to as 4) as follows:

* Stage 0: The U.S. is stratified by geography and proportion of minority populations
* Stage 1: Within strata, counties are randomly selected
* Stage 2: Within counties, city blocks are randomly selected
* Stage 3: Within city blocks, households randomly selected
* Stage 4: Within households, people randomly selected

In the NHANES data, we therefore have strata of counties, followed by 3 levels of clustering.  The two important design variables in NHANESraw are SDMVSTRA, which contains the strata assignment for each unit, and SDMVPSU, which contains the cluster id within a given stratum.  It is common practice to just name the top level of clustering.  The variable we use is then county, which is variable SDMVPSU, which has 3 values 1-3 representing the 1 to 3 counties samplied within each strata.  As the cluster ids are within each strata, we use the nest = TRUE argument.  

Minority populations are more liekly to be sampled, so to account for this we need to weight the data.  The raw weight in the dataset is 2009 to 2012 - four years.  The weight variable in the dataset - WTMEC2YR is for two years.  So we first need to divide each weight by two, to give a single year's weight.

```{r}
# Load the data
library(NHANES)
data(NHANESraw)

# Create a single year's weight
NHANESraw <- mutate(NHANESraw, WTMEC4YR = WTMEC2YR/2)

#Create table of average survey weights by race
tab_weights <- NHANESraw %>%
  group_by(Race1) %>%
  summarize(avg_wt = mean(WTMEC4YR))

#Print the table
tab_weights
```

Next we can specify our survey design element, then count the number of clusters in our design and finally the sample size in each cluster.  The n_distinct() command counts the number of unique values, we use this command to determine the total number of clusters in NHANESraw.  For the sample size, we just use the count function.

```{r}
# Specify the NHANES design
NHANES_design <- svydesign(data = NHANESraw, strata = ~SDMVSTRA, id = ~SDMVPSU, nest = TRUE, weights = ~WTMEC4YR)

# Print summary of design
summary(NHANES_design)

# Number of clusters
NHANESraw %>%
  summarize(n_clusters = n_distinct(SDMVSTRA, SDMVPSU))

# Sample sizes in clusters
NHANESraw %>%
  count(SDMVSTRA, SDMVPSU)
```


## Exploring categorical data

Having now created our survey design for NHANES, we can use this design to correctly analyse our survey data.  The svytable (survey table) command will correctly calculate proportions, using the survey design component.  The NHANES variable, Depressed, gives the self-reported frequency in which a participant felt depressed, it is only recorded for Adults.

```{r}
# Specify the survey design
NHANESraw <- mutate(NHANESraw, WTMEC4YR = .5 * WTMEC2YR)
NHANES_design <- svydesign(data = NHANESraw, strata = ~SDMVSTRA, id = ~SDMVPSU, nest = TRUE, weights = ~WTMEC4YR)

# Determine the levels of Depressed
levels(NHANESraw$Depressed)

# Construct a frequency table of Depressed
tab_w <- svytable(~Depressed, design = NHANES_design)

# Determine class of tab_w
class(tab_w)

# Display tab_w
tab_w
```

Next we can represent this visualising, but first we need to create our proportions table:

```{r}
# Add proportions to table
tab_w <- tab_w %>%
  as.data.frame() %>%
  mutate(Prop = Freq/sum(Freq))

# Create a barplot
ggplot(data = tab_w, aes(x = Depressed, y = Prop)) + 
  geom_col() + 
  coord_flip()
```

We often want to compare two variables together, for instance, comparing General Health to levels of Depression.  To do so, we create a contingency table. 

```{r}
# Construct and display our frequency tables
tab_D <- svytable(~Depressed,
           design = NHANES_design)
tab_D

tab_H <- svytable(~HealthGen,
           design = NHANES_design)
tab_H

tab_DH <- svytable(~Depressed + HealthGen,
           design = NHANES_design)
tab_DH
```

Next we usually want to answer some question with our data, like "What is the probability that a person in excellent health suffers from depression?" and "Are depression rates lower for healthier people?" which we do so by creating conditional probabilities.

```{r}
# Add conditional proportions to tab_DH
tab_DH_cond <- tab_DH %>%
    as.data.frame() %>%
    group_by(HealthGen) %>%
    mutate(n_HealthGen = sum(Freq), Prop_Depressed = Freq/n_HealthGen) %>%
    ungroup()

# Print tab_DH_cond
tab_DH_cond

# Create a segmented bar graph of the conditional proportions in tab_DH_cond
ggplot(data = tab_DH_cond,
       mapping = aes(x = HealthGen, y = Prop_Depressed, fill = Depressed)) + 
  geom_col() + 
  coord_flip() + 
  scale_y_continuous(labels = scales::percent) # without this the bar chart is a decimal of 0 to 1

```

We can also estimate the total counts and interactions between variables, also calculating se.

```{r}
# Estimate the totals for combos of Depressed and HealthGen
tab_totals <- svytotal(x = ~interaction(Depressed, HealthGen),
                     design = NHANES_design,
                     na.rm = TRUE)

# Print table of totals
tab_totals
```

And calculate survey means for the variable

```{r}
# Estimate the means for combos of Depressed and HealthGen
tab_means <- svymean(x = ~interaction(Depressed, HealthGen),
              design = NHANES_design,
              na.rm = TRUE)

# Print table of means
tab_means
```

Here we see that the survey results estimate that 10.4% of people are not depressed and believe their health is excellent.

Next we test whether or not there is an association between depression level and perceived health using a chi squared test. The p-value of the chi squared test tells us how consistent our sample results are with the assumption that depression and perceived health are not related - a high p-value means we should accept the null hypothesis that there is no relationship i.e. the relationship we are seeing is due to chance.

```{r}
# Run a chi square test between Depressed and HealthGen
svychisq(~Depressed + HealthGen, 
    design = NHANES_design, 
    statistic = "Chisq")
```
We have a very small p-value suggesting the two are related.

We can use the knowledge of these steps to look at other situations - here we will look at whether there is a statistical relationship between homeownership and education level.

```{r}
# Construct a contingency table
tab <- svytable(~HomeOwn + Education, design = NHANES_design)

# Add conditional proportion of levels of HomeOwn for each educational level
tab_df <- as.data.frame(tab) %>%
  group_by(Education) %>%
  mutate(n_Education = sum(Freq), Prop_HomeOwn = Freq/n_Education) %>%
  ungroup()

# Create a segmented bar graph
ggplot(data = tab_df, mapping = aes(x = Education, y = Prop_HomeOwn, fill = HomeOwn)) + 
  geom_col() + 
  coord_flip() +
   scale_y_continuous(labels = scales::percent) # without this the bar chart is a decimal of 0 to 1

# Run a chi square test
svychisq(~HomeOwn + Education, design = NHANES_design, statistic = "Chisq")
```


## Exploring quantitative data

Survey data is observational and not experimental, so we can't conclude causation, however survey data can be useful to explore relationships and possible avenues of enquiry.  The survey package comes with a number of functions that can help us explore data, which considering the survey design.

We can use the data to see how much sleep people get and whether it varies by gender.  First, we need to filter out the under 16s as they are not asked this question, this is done using the variable SleepHrsNight which is only asked to the over 16s.  Then we use the svyby which is similar to the groupby command from dplyr and will give us a two way table.

```{r}
# Compute the survey-weighted mean
svymean(x = ~SleepHrsNight, 
        design = NHANES_design,
        na.rm = TRUE)

# Compute the survey-weighted mean by Gender
svyby(formula = ~SleepHrsNight, 
    by = ~Gender, 
    design = NHANES_design, 
    FUN = svymean, 
    na.rm = TRUE, 
    keep.names = FALSE)
```

We might also be interested in the distribution of this variable, by looking at the lowest 1%, the median and so on.  We can use the svyquantile to calculate these values.  We can then look at the median value for both men and women

```{r}
# Compute the survey-weighted quantiles
svyquantile(x = ~SleepHrsNight, 
            design = NHANES_design, 
            na.rm = TRUE, 
            quantiles = c(0.01, 0.25, 0.5, 0.75, .99))

# Compute the survey-weighted quantiles by Gender
svyby(formula = ~SleepHrsNight, 
      by = ~Gender, 
      design = NHANES_design, 
      FUN = svyquantile, 
      na.rm = TRUE, 
      quantiles = 0.5, 
      keep.rows = FALSE, 
      keep.var = FALSE)
```

We can also graph this data - first we create our table which we then use to create a plot.

```{r}
# Compute the survey-weighted mean by Gender
out <- svyby(formula = ~SleepHrsNight, 
             by = ~Gender, 
             design = NHANES_design, 
             FUN = svymean, 
             na.rm = TRUE, 
             keep.names = FALSE)
             
# Construct a bar plot of average sleep by gender
ggplot(data = out, mapping = aes(x = Gender, y = SleepHrsNight)) +
  geom_col() + 
  labs(y = "Average Nightly Sleep")
```

We might be interested in adding error bars to our chart.  This is achieved by first creating the upper and lower bounds, then adding them to the plot.

```{r}
# Add lower and upper columns to out
out_col <- mutate(out, 
                  lower = SleepHrsNight - 2*se, 
                  upper = SleepHrsNight + 2*se)

# Construct a bar plot of average sleep by gender with error bars
ggplot(data = out_col, 
       mapping = aes(x = Gender, y = SleepHrsNight, 
                     ymin = lower, ymax = upper)) +
  geom_col(fill = "gold") +
  labs(y = "Average Nightly Sleep") +
  geom_errorbar(width = 0.7)
```

We may want to represent our data as a histogram. Here we map sleep hours and the weight.

```{r}
# Create a histogram with a set binwidth
ggplot(data = NHANESraw,
       mapping = aes(x = SleepHrsNight, weight = WTMEC4YR)) + 
  geom_histogram(binwidth = 1,
                 color = "white") +
  labs(x = "Hours of Sleep")
```

Or we may want to represent the data as density plot.  As there are some missing values in our data and density plots are probabilities, we need to do some data wrangling first.

```{r}
# Density plot of sleep faceted by gender
NHANESraw %>%
    filter(!is.na(SleepHrsNight), !is.na(Gender)) %>%
    group_by(Gender) %>%
    mutate(WTMEC4YR_std = WTMEC4YR/sum(WTMEC4YR)) %>%
    ggplot(mapping = aes(x = SleepHrsNight, weight = WTMEC4YR_std)) + 
        geom_density(bw = 0.6,  fill = "gold") +
        labs(x = "Hours of Sleep") + 
        facet_wrap(~Gender, labeller = "label_both")
```

Now we might want to calculate a t-test statistic, to see whether our data is due to chance or some underlying relationship.  To take account of our survey design, we use the svyttest() function.

```{r}
# Run a survey-weighted t-test
svyttest(formula = SleepHrsNight ~ Gender, design = NHANES_design)
```

Next, let's look at another example, whether or not the total cholesterol varies, on average, between physically active and inactive Americans.  

First we calculate survey mean.

```{r}
# Find means of total cholesterol by whether or not active 
out <- svyby(formula = ~TotChol,
           by = ~PhysActive, 
           design = NHANES_design,
           FUN = svymean, 
           na.rm = TRUE, 
           keep.names = FALSE)
```

Next we create a bar chart.

```{r}
ggplot(data = out, mapping = aes(x = PhysActive, y = TotChol)) +
  geom_col()
```

Then calculate the survey t-test.

```{r}
# Run a survey-weighted t-test
svyttest(formula = TotChol ~ PhysActive, design = NHANES_design)
```

## Modeling quantitative data

When we want to plot two quantitive variables we can use a scatterplot.  We should also be mindful to take account of the survey design, including weighting, so that we not only show who has responded, but what wider population they represent.

First we filter the data to only include the over 20s.  Then we create a scatterplot without the weight variable first.

```{r}
# Create dataset with only 20 year olds
NHANES20 <- filter(NHANESraw, Age == 20)

# Construct scatter plot
ggplot(data = NHANES20, 
       mapping = aes(x = Height, y = Weight)) + 
    geom_point(alpha = 0.3) + 
    guides(size = FALSE)

```

Next we create a plot which does take into account our weight variable.

```{r}
# Construct bubble plot
ggplot(data = NHANES20, 
       mapping = aes(x = Height, y = Weight, size = WTMEC4YR)) + 
    geom_point(alpha = 0.3) + 
    guides(size = FALSE)
```

Another way to present the density rather than bubble size is to use the colour saturation.  

```{r}
# Construct a scatter plot
ggplot(data = NHANES20, 
       mapping = aes(x = Height, y = Weight, color = WTMEC4YR)) +
    geom_point(alpha = 0.3) + 
    guides(color = FALSE)
```

Or yet another way is to set the alpha value dependent on the weight variable.

```{r}
# Construct a scatter plot
ggplot(data = NHANES20, 
       mapping = aes(x = Height, y = Weight, alpha = WTMEC4YR)) +
    geom_point(alpha = 0.3) + 
    guides(alpha = FALSE)
```

We may be interested in plotting the results witn the presence of another variable, for instance, Gender.  This can be achieved as follows.

```{r}
# Add gender to plot
ggplot(data = NHANES20,
       mapping = aes(x = Height, y = Weight, size = WTMEC4YR, color = Gender)) + 
    geom_point(alpha = 0.3) + 
    guides(size = FALSE)
```

Or we can use alpha (transparency) to represent weight rather than bubble size.

```{r}
# Add gender to plot
ggplot(data = NHANES20,
       mapping = aes(x = Height, y = Weight, alpha = WTMEC4YR, color = Gender)) + 
    geom_point(alpha = 0.3) + 
    guides(alpha = FALSE)
```

We can also add a line of best first using the geom_smooth command.

```{r}
# Bubble plot with linear of best fit
ggplot(data = NHANESraw, mapping = aes(x = Height, y = Weight, size = WTMEC4YR)) + 
  geom_point(alpha = 0.1) + 
  guides(size = FALSE) + 
  geom_smooth(method = "lm", se = FALSE, mapping = aes(weight = WTMEC4YR))
```

Here the trend is not really linear, so we can adapt the smoothing line to better represent the data, in this instance we can use polynomial curve lines - an orange for quadratic (power of 2) and a red one for cubic (power of 3).

```{r}
# Add quadratic curve and cubic curve
ggplot(data = NHANESraw, mapping = aes(x = Height, y = Weight, size = WTMEC4YR)) + 
  geom_point(alpha = 0.1) + 
  guides(size = FALSE) + 
  geom_smooth(method = "lm", se = FALSE, mapping = aes(weight = WTMEC4YR)) +
  geom_smooth(method = "lm", se = FALSE, mapping = aes(weight = WTMEC4YR), formula = y ~ poly(x,2), color = "orange") +
  geom_smooth(method = "lm", se = FALSE, mapping = aes(weight = WTMEC4YR), formula = y ~ poly(x,3), color = "red")
```

If we want to compare how the trend lines differ by gender, both with and without the survey weights, this can be acheived using two sets of lines of best fit being dashed to show the unweighted data.  Notice the results for females are different when weighted, the results for males are more similar.

```{r}
# Add non-survey-weighted trend lines to bubble plot
ggplot(data = NHANES20, mapping = aes(x = Height, y = Weight, size = WTMEC4YR, color = Gender)) + 
  geom_point(alpha = 0.1) + 
  guides(size = FALSE) + 
  geom_smooth(method = "lm", se = FALSE, linetype = 2)

# Add survey-weighted trend lines
ggplot(data = NHANES20, mapping = aes(x = Height, y = Weight, size = WTMEC4YR, color = Gender)) + 
  geom_point(alpha = 0.1) + 
  guides(size = FALSE) + 
  geom_smooth(method = "lm", se = FALSE, linetype = 2) + 
  geom_smooth(method = "lm", se = FALSE, mapping = aes(weight = WTMEC4YR))
```

We often want to understand the coefficients of a regression line, such as those previously plotted.  This can be done usign the glm function.

```{r}
# Subset survey design object to only include 20 year olds
NHANES20_design <- subset(NHANES_design, Age == 20)

# Build a linear regression model
mod <- svyglm(Weight ~ Height, design = NHANES20_design)

# Print summary of the model
summary(mod)
```

The null hypothesis, which the coefficients are testing, is that there is no linear relationship between the variables, with the alternative hypothesis being that there is a linear relationship with the variables we have modelled.  The slope t-value is 6.072 with a very small and significant p-value.

As we saw previously, the slopes of the regression line varied depending on whether the gender was male or female.  We can incorporate this into our model, but note that the variable should be coded as a dummy var.  In addition, the t-test statistic now indicates whether that variable should be included in our model given the other variables listed in our model i.e. having controlled for the other variables.  

```{r}
# Build a linear regression model same slope
mod1 <- svyglm(Weight ~ Height + Gender, design = NHANES20_design)

# Print summary of the same slope model
summary(mod1)
```

We also saw that the intercepts varied, not just the slopes, when looking at gender.  We can model this using interaction terms (*).

```{r}
# Build a linear regression model different slopes
mod2 <- svyglm(Weight ~ Height * Gender, design = NHANES20_design)

# Print summary of the different slopes model
summary(mod2)
```

The second model where the slopes vary seems to have a statistically significant t value for the slope co-efficient, but in our first model the intercept only co-efficient was not statistically significant.

Finally, let's look at a different example.  Here we build a model to predict, BPSysAve, a person's systolic blood pressure reading, using BPDiaAve, a person's diastolic blood pressure reading and Diabetes, whether or not they were diagnosed with diabetes.  We produce a scatterplot, then create a simple model, then a more complex model where the slopes vary.

```{r}
# Plot BPDiaAve and BPSysAve by Diabetes and include trend lines
tidyr::drop_na(NHANESraw, Diabetes) %>%
ggplot(mapping = aes(x = BPDiaAve, y = BPSysAve, size = WTMEC4YR, color = Diabetes)) + 
    geom_point(alpha = 0.2) + 
    guides(size = FALSE) + 
    geom_smooth(method = "lm", se = FALSE, mapping = aes(weight = WTMEC4YR))

# Build simple linear regression model
mod1 <- svyglm(BPSysAve ~ BPDiaAve, design = NHANES_design)

# Build model with different slopes
mod2 <- svyglm(BPSysAve ~ BPDiaAve * Diabetes, design = NHANES_design)

# Summarize models
summary(mod1)
summary(mod2)
```

Note - we should probably drop those values where the BPDiaAve appears to be 0, since this could be a missing value.
